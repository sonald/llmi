# llmi
llm on the terminal

## TODO
- [ ] highlighting
- [ ] Tab to change focus
- [ ] chat history
- [ ] ollama support
- [ ] llm switch (support multiple llm endpoints)
- [ ] parallel-multi-llm inference